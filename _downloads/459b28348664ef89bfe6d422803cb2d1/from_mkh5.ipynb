{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Options for converting to mne.Raw\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport mne\nfrom mkpy import mkh5\nfrom mkpy.io import mkh5mne\n\nmne.viz.set_browser_backend(\"matplotlib\")  # for docs generation\n\n# FYI\nconda_env = os.environ[\"CONDA_DEFAULT_ENV\"]\nprint(\"conda env\", conda_env)\nfor pkg in [mkh5, mne]:\n    print(pkg.__name__, pkg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### mkh5 data file format in a nutshell\nThis sample mkh5 data is for a single subject in an auditory oddball paradigm with\npreviously set epoch tables.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "H5_F = \"../mkh5_data/sub000p3.h5\"\nh5_data = mkh5.mkh5(H5_F)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stimulus and response events of interest have been tagged with an mkh5 codemap and stored\nas named epochs tables ``mkh5.set_epochs(...)``. The epochs tables are whatever was deemed\nuseful.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_data.get_epochs_table_names()\n\n# The epochs tables have index information about where to find the\n# events in the mkh5 file, the experimental variables from\n# the codemap, and the epoch discrete time interval specs, relative\n# to the current mkh5 datablock.\nepochs_table = h5_data.get_epochs_table(\"ms1500\")\nepochs_table[\n    [\n        \"epoch_id\",\n        \"data_group\",\n        \"dblock_path\",  # HDF5 data lookup info\n        \"log_evcodes\",\n        \"log_ccodes\",\n        \"log_flags\",  # event code info\n        \"tone\",\n        \"stim\",\n        \"accuracy\",\n        \"acc_type\",  # codemap tags\n        \"diti_t_0\",\n        \"diti_hop\",\n        \"diti_len\",  # epoch t_0, offset, duration\n    ]\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mkh5 EEG and event channel data are stored in datablocks (HDF5\nDataset) at the end of an HDF5 \"slash\" path:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h5_data.dblock_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Electrode locations\n\nConverting mkh5 to mne.Raw **requires** an mkh5 format apparatus map\nwith the coordinate space, fiducal landmarks and electrode\nlocations. If the appartus map was included with the YAML .yhdr when\nthe mkh5 file was created it will be used automatically.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne_raw = mkh5mne.from_mkh5(H5_F)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This sample mkh5 data file was created with coordinates for an\nidealized \"average\" head, based on 3D digitized\nlocations. Head-shaped locations are called for when working with\nrealistic head geometry in MNE but they don't line up exactly with\ncircular topographic maps.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = mne.viz.plot_sensors(mne_raw.info, sphere=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If original .yhdr did not include an apparatus map or a different\nset of locations is preferred, they can be specified when converting\nto MNE and used instead.\n\nThis map overrides the original head-shaped electrode locations with\nspherical 3D coordinates which are unrealistic as human head\ngeometry but line up neatly with circles for painting pretty 2D\npictures.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne_raw_a = mkh5mne.from_mkh5(H5_F, apparatus_yaml=\"mne_32chan_xyz_spherical.yml\")\n_ = mne.viz.plot_sensors(mne_raw_a.info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Selecting which datablocks to convert to mne.Raw\n\nBy default :py:meth:`.read_raw_mkh5` converts the entire mkh5 file.\nThe mkh5 data groups and EEG datablocks are appended in the order\norder returned by :py:meth:`.dblock_paths` which sorts HDF5 the HDF5\npaths to data group alphabetically and preserves data block order\nwithin each group.\n\nAn mkh5 file might have multiple subjects or experiments, if\nyou don't want to make it all one mne.Raw object, you can\n select which data blocks to convert with ``datablock_paths=``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne_raw_b = mkh5mne.read_raw_mkh5(\n    H5_F, dblock_paths=[\"sub000/dblock_0\", \"sub000/dblock_1\"]\n)\n\n# only dblock_0 and dblock_1 appear in the Raw data\nmne_raw_b.annotations.description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Marking garv artifacts in mne.Raw\n\nIf you prepared the mkh5 file with the .log file log_flags set to\ntrack garv artifacts (``avg -x``) you can automatically mark the\ngarv artifacts in the mne.Raw with BAD_garv mne.Annotations by\npassing in the ``garv_annotations`` options.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Mark *all* the log stim and response events events with lots of overlap\nmne_raw_c = mkh5mne.from_mkh5(\n    H5_F,\n    garv_annotations={\n        \"event_channel\": \"log_flags\",\n        \"tmin\": -500,\n        \"tmax\": 1000,\n        \"units\": \"ms\",\n    },\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``avg -x`` flags **all** event codes in the log that fail a test whether or\n   not these are the timelocking events of interest.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "annotation intervals for log events upstream or downstream of the\ntimelock of interest may overlap the epoch interval and\n``mne.Epochs(..., reject_by_annotation=True)`` will exclude them for\nbeing (partially) polluted. To avoid this, define your mkh5 codemap\nand named epochs table so that epochs of interest do not overlap and\nuse that same-named MNE event channel to set the garv annoations\nlike so:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mne_raw_c = mkh5mne.from_mkh5(\n    H5_F,\n    garv_annotations={\n        \"event_channel\": \"ms1500\",\n        \"tmin\": -500,\n        \"tmax\": 1000,\n        \"units\": \"ms\",\n    },\n)\n\n\nmne_raw_c.plot(scalings={\"eeg\": 5e-5, \"eog\": 1e-4}, start=10.0, n_channels=39)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}